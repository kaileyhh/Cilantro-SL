{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160677d9-e696-401a-878c-40042ca904c0",
   "metadata": {},
   "source": [
    "# reduce to 256 using PCA, and then generate a df with its gene embeddings (w/ delta embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d416c921-746d-480f-855a-67e421b025cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "model = AutoModel.from_pretrained(\"h4duan/PAIR-esm2\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9066998-1465-4ef7-b87f-8e0b43c7da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(protein):\n",
    "  ids = tokenizer(protein, return_tensors=\"pt\", padding=True, max_length=1024, truncation=True, return_attention_mask=True)\n",
    "  input_ids = torch.tensor(ids['input_ids']).to(\"cuda\")\n",
    "  attention_mask = torch.tensor(ids['attention_mask']).to(\"cuda\")\n",
    "  with torch.no_grad():\n",
    "    embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask).last_hidden_state\n",
    "  return torch.mean(embedding_repr, dim=1)\n",
    "\n",
    "def extract_features_batch(proteins):\n",
    "  ids = tokenizer(proteins, return_tensors=\"pt\", padding=True, max_length=1024, truncation=True, return_attention_mask=True)\n",
    "  input_ids = torch.tensor(ids['input_ids']).to(\"cuda\")\n",
    "  attention_mask = torch.tensor(ids['attention_mask']).to(\"cuda\")\n",
    "  with torch.no_grad():\n",
    "    embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask).last_hidden_state\n",
    "  attention_mask = attention_mask.unsqueeze(-1)\n",
    "  attention_mask = attention_mask.expand(-1, -1, embedding_repr.size(-1))\n",
    "  masked_embedding_repr = embedding_repr * attention_mask\n",
    "  sum_embedding_repr = masked_embedding_repr.sum(dim=1)\n",
    "  non_zero_count = attention_mask.sum(dim=1) \n",
    "  mean_embedding_repr = sum_embedding_repr / non_zero_count\n",
    "  return mean_embedding_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b3eba0-2b98-425f-8149-a9fb99b1dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_890144/281650576.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(ids['input_ids']).to(\"cuda\")\n",
      "/tmp/ipykernel_890144/281650576.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(ids['attention_mask']).to(\"cuda\")\n"
     ]
    }
   ],
   "source": [
    "protein = [\"AETCZAO\"]\n",
    "\n",
    "feature = extract_feature(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "530c195b-ee4d-4792-8bb6-82fb86d43803",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_mapping = torch.load('/work/magroup/shared/Heimdall/data/pretrained_embeddings/ESM2/protein_map_human_ensembl.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "287ac110-e42e-4346-8340-6bbecf83b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/work/magroup/kaileyhu/res/perturbed/gf_12L_30M_i2048_SL/ESM_df\"\n",
    "\n",
    "df = pd.read_hdf(f\"{path}/ESM_emb_mat.h5\", \"table\")\n",
    "df.set_index(\"Unnamed: 0\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fc6e291-ce3c-4a98-9611-29ba45889fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_path = \"/work/magroup/kaileyhu/Geneformer/geneformer/ensembl_mapping_dict_gc95M.pkl\"\n",
    "        \n",
    "with open(ensembl_path, \"rb\") as f:\n",
    "    id_gene_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1397f7f9-3314-4bb2-ad28-01f974eec794",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id_dict = {}\n",
    "for key, value in id_gene_dict.items():\n",
    "    if value in gene_id_dict:\n",
    "        continue\n",
    "    gene_id_dict[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5269d8f6-3cb9-4a4d-94f0-fbd8d8bb34d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_890144/281650576.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(ids['input_ids']).to(\"cuda\")\n",
      "/tmp/ipykernel_890144/281650576.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(ids['attention_mask']).to(\"cuda\")\n"
     ]
    }
   ],
   "source": [
    "pair_mapping = {}\n",
    "\n",
    "genes = []\n",
    "# ens_ids = []\n",
    "for key in esm_mapping.keys():\n",
    "    \n",
    "    if key not in gene_id_dict:\n",
    "        genes.append(key)\n",
    "    else:\n",
    "        gene = gene_id_dict[key]\n",
    "        genes.append(gene)\n",
    "\n",
    "features = extract_features_batch(genes)\n",
    "feature_cpu = [x.cpu() for x in features]\n",
    "pair_mapping = dict(zip(esm_mapping.keys(), feature_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e613cde4-717d-4131-a06e-f11d4a8b43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df = pd.DataFrame(pair_mapping).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac7ce969-ae4f-4ded-9415-aa102cdb6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08060569-59e3-4d5a-8c86-d004c71b038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=256)\n",
    "\n",
    "principalComponents = pca.fit_transform(pair_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0ac229b-4ba9-4d36-89f1-da2fbac53bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(data = principalComponents, columns = [f\"pc {i}\" for i in range(256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ada5bbd-3c72-4cf1-8baa-75412e2da897",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.index = pair_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58b4b772-06d1-44d0-8e4e-d9969da7105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.to_csv(\"/work/magroup/kaileyhu/res/gene_embeddings/PAIR_pca_256.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b1807ae-0849-48ab-9003-bc6223b6e279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc 0</th>\n",
       "      <th>pc 1</th>\n",
       "      <th>pc 2</th>\n",
       "      <th>pc 3</th>\n",
       "      <th>pc 4</th>\n",
       "      <th>pc 5</th>\n",
       "      <th>pc 6</th>\n",
       "      <th>pc 7</th>\n",
       "      <th>pc 8</th>\n",
       "      <th>pc 9</th>\n",
       "      <th>...</th>\n",
       "      <th>pc 246</th>\n",
       "      <th>pc 247</th>\n",
       "      <th>pc 248</th>\n",
       "      <th>pc 249</th>\n",
       "      <th>pc 250</th>\n",
       "      <th>pc 251</th>\n",
       "      <th>pc 252</th>\n",
       "      <th>pc 253</th>\n",
       "      <th>pc 254</th>\n",
       "      <th>pc 255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000121410</th>\n",
       "      <td>-2.939927</td>\n",
       "      <td>0.235590</td>\n",
       "      <td>0.245271</td>\n",
       "      <td>1.313475</td>\n",
       "      <td>0.139536</td>\n",
       "      <td>0.443911</td>\n",
       "      <td>-0.536603</td>\n",
       "      <td>1.792289</td>\n",
       "      <td>0.575737</td>\n",
       "      <td>0.798791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131530</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>-0.012133</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>-0.264293</td>\n",
       "      <td>0.157491</td>\n",
       "      <td>0.093152</td>\n",
       "      <td>0.086953</td>\n",
       "      <td>0.075399</td>\n",
       "      <td>0.171969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000148584</th>\n",
       "      <td>2.112873</td>\n",
       "      <td>-1.344812</td>\n",
       "      <td>0.445607</td>\n",
       "      <td>0.291106</td>\n",
       "      <td>-1.373380</td>\n",
       "      <td>0.755434</td>\n",
       "      <td>-0.878596</td>\n",
       "      <td>0.541939</td>\n",
       "      <td>-0.461665</td>\n",
       "      <td>-1.120564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>-0.091927</td>\n",
       "      <td>0.273974</td>\n",
       "      <td>-0.097112</td>\n",
       "      <td>0.064122</td>\n",
       "      <td>-0.120927</td>\n",
       "      <td>-0.258579</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.048188</td>\n",
       "      <td>-0.178412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000175899</th>\n",
       "      <td>0.424642</td>\n",
       "      <td>-0.603142</td>\n",
       "      <td>-1.718002</td>\n",
       "      <td>-0.538989</td>\n",
       "      <td>-1.827814</td>\n",
       "      <td>1.658736</td>\n",
       "      <td>-1.618316</td>\n",
       "      <td>1.161420</td>\n",
       "      <td>-0.272878</td>\n",
       "      <td>-0.359440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126916</td>\n",
       "      <td>0.239926</td>\n",
       "      <td>-0.279099</td>\n",
       "      <td>0.267309</td>\n",
       "      <td>-0.184580</td>\n",
       "      <td>-0.251052</td>\n",
       "      <td>0.046126</td>\n",
       "      <td>0.301693</td>\n",
       "      <td>-0.233983</td>\n",
       "      <td>-0.106899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000166535</th>\n",
       "      <td>4.252601</td>\n",
       "      <td>0.937075</td>\n",
       "      <td>-2.469287</td>\n",
       "      <td>0.488562</td>\n",
       "      <td>0.406097</td>\n",
       "      <td>0.782439</td>\n",
       "      <td>2.453494</td>\n",
       "      <td>0.021551</td>\n",
       "      <td>0.808722</td>\n",
       "      <td>0.142757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034944</td>\n",
       "      <td>0.025370</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>0.085839</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>-0.123735</td>\n",
       "      <td>0.066340</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.027567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000184389</th>\n",
       "      <td>-0.781904</td>\n",
       "      <td>-0.357991</td>\n",
       "      <td>0.616421</td>\n",
       "      <td>-1.250940</td>\n",
       "      <td>-0.266191</td>\n",
       "      <td>-0.874253</td>\n",
       "      <td>0.914282</td>\n",
       "      <td>0.107264</td>\n",
       "      <td>0.503933</td>\n",
       "      <td>-0.035998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115956</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.109264</td>\n",
       "      <td>-0.090908</td>\n",
       "      <td>-0.141917</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>-0.153174</td>\n",
       "      <td>0.056722</td>\n",
       "      <td>0.097499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000203995</th>\n",
       "      <td>3.115587</td>\n",
       "      <td>2.058678</td>\n",
       "      <td>0.800066</td>\n",
       "      <td>-0.084726</td>\n",
       "      <td>-0.825784</td>\n",
       "      <td>-0.154372</td>\n",
       "      <td>1.475193</td>\n",
       "      <td>0.135988</td>\n",
       "      <td>-0.246537</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058871</td>\n",
       "      <td>-0.041181</td>\n",
       "      <td>-0.049788</td>\n",
       "      <td>-0.138405</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>-0.077362</td>\n",
       "      <td>-0.268796</td>\n",
       "      <td>-0.067865</td>\n",
       "      <td>0.114491</td>\n",
       "      <td>-0.244308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000162378</th>\n",
       "      <td>-1.432864</td>\n",
       "      <td>-1.578524</td>\n",
       "      <td>1.264478</td>\n",
       "      <td>-1.438484</td>\n",
       "      <td>-0.374076</td>\n",
       "      <td>-0.012406</td>\n",
       "      <td>1.622662</td>\n",
       "      <td>-0.210969</td>\n",
       "      <td>-0.952287</td>\n",
       "      <td>-0.723893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026867</td>\n",
       "      <td>-0.054563</td>\n",
       "      <td>0.081663</td>\n",
       "      <td>-0.094380</td>\n",
       "      <td>-0.077367</td>\n",
       "      <td>0.162979</td>\n",
       "      <td>0.211054</td>\n",
       "      <td>0.153263</td>\n",
       "      <td>-0.008993</td>\n",
       "      <td>0.012680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000159840</th>\n",
       "      <td>-1.064318</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.556401</td>\n",
       "      <td>-0.778084</td>\n",
       "      <td>0.378676</td>\n",
       "      <td>-0.399659</td>\n",
       "      <td>-0.548248</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>-0.381778</td>\n",
       "      <td>0.636120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100690</td>\n",
       "      <td>-0.146181</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>-0.097892</td>\n",
       "      <td>-0.253979</td>\n",
       "      <td>-0.038200</td>\n",
       "      <td>-0.027520</td>\n",
       "      <td>-0.011465</td>\n",
       "      <td>-0.018991</td>\n",
       "      <td>-0.073372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000074755</th>\n",
       "      <td>-1.159131</td>\n",
       "      <td>0.117286</td>\n",
       "      <td>1.549862</td>\n",
       "      <td>-0.863698</td>\n",
       "      <td>0.811906</td>\n",
       "      <td>0.122840</td>\n",
       "      <td>0.700316</td>\n",
       "      <td>-0.419327</td>\n",
       "      <td>-0.514220</td>\n",
       "      <td>-0.677741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091692</td>\n",
       "      <td>0.072423</td>\n",
       "      <td>0.118722</td>\n",
       "      <td>-0.106668</td>\n",
       "      <td>-0.068032</td>\n",
       "      <td>-0.199963</td>\n",
       "      <td>0.035639</td>\n",
       "      <td>-0.043847</td>\n",
       "      <td>-0.208945</td>\n",
       "      <td>-0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000036549</th>\n",
       "      <td>1.327665</td>\n",
       "      <td>-1.008955</td>\n",
       "      <td>-0.655824</td>\n",
       "      <td>-0.677693</td>\n",
       "      <td>-2.637185</td>\n",
       "      <td>2.377972</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.190569</td>\n",
       "      <td>-1.320892</td>\n",
       "      <td>-0.158486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002180</td>\n",
       "      <td>-0.080878</td>\n",
       "      <td>0.216868</td>\n",
       "      <td>-0.063773</td>\n",
       "      <td>-0.156554</td>\n",
       "      <td>0.124893</td>\n",
       "      <td>0.034833</td>\n",
       "      <td>0.228654</td>\n",
       "      <td>0.060244</td>\n",
       "      <td>0.142755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19790 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pc 0      pc 1      pc 2      pc 3      pc 4      pc 5  \\\n",
       "ENSG00000121410 -2.939927  0.235590  0.245271  1.313475  0.139536  0.443911   \n",
       "ENSG00000148584  2.112873 -1.344812  0.445607  0.291106 -1.373380  0.755434   \n",
       "ENSG00000175899  0.424642 -0.603142 -1.718002 -0.538989 -1.827814  1.658736   \n",
       "ENSG00000166535  4.252601  0.937075 -2.469287  0.488562  0.406097  0.782439   \n",
       "ENSG00000184389 -0.781904 -0.357991  0.616421 -1.250940 -0.266191 -0.874253   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "ENSG00000203995  3.115587  2.058678  0.800066 -0.084726 -0.825784 -0.154372   \n",
       "ENSG00000162378 -1.432864 -1.578524  1.264478 -1.438484 -0.374076 -0.012406   \n",
       "ENSG00000159840 -1.064318  0.294862  0.556401 -0.778084  0.378676 -0.399659   \n",
       "ENSG00000074755 -1.159131  0.117286  1.549862 -0.863698  0.811906  0.122840   \n",
       "ENSG00000036549  1.327665 -1.008955 -0.655824 -0.677693 -2.637185  2.377972   \n",
       "\n",
       "                     pc 6      pc 7      pc 8      pc 9  ...    pc 246  \\\n",
       "ENSG00000121410 -0.536603  1.792289  0.575737  0.798791  ...  0.131530   \n",
       "ENSG00000148584 -0.878596  0.541939 -0.461665 -1.120564  ... -0.003471   \n",
       "ENSG00000175899 -1.618316  1.161420 -0.272878 -0.359440  ...  0.126916   \n",
       "ENSG00000166535  2.453494  0.021551  0.808722  0.142757  ...  0.034944   \n",
       "ENSG00000184389  0.914282  0.107264  0.503933 -0.035998  ... -0.115956   \n",
       "...                   ...       ...       ...       ...  ...       ...   \n",
       "ENSG00000203995  1.475193  0.135988 -0.246537  0.599952  ... -0.058871   \n",
       "ENSG00000162378  1.622662 -0.210969 -0.952287 -0.723893  ...  0.026867   \n",
       "ENSG00000159840 -0.548248  0.838446 -0.381778  0.636120  ...  0.100690   \n",
       "ENSG00000074755  0.700316 -0.419327 -0.514220 -0.677741  ... -0.091692   \n",
       "ENSG00000036549  0.403104  0.190569 -1.320892 -0.158486  ... -0.002180   \n",
       "\n",
       "                   pc 247    pc 248    pc 249    pc 250    pc 251    pc 252  \\\n",
       "ENSG00000121410  0.002528 -0.012133  0.133362 -0.264293  0.157491  0.093152   \n",
       "ENSG00000148584 -0.091927  0.273974 -0.097112  0.064122 -0.120927 -0.258579   \n",
       "ENSG00000175899  0.239926 -0.279099  0.267309 -0.184580 -0.251052  0.046126   \n",
       "ENSG00000166535  0.025370 -0.008613  0.085839  0.006990 -0.123735  0.066340   \n",
       "ENSG00000184389  0.010742  0.020842  0.109264 -0.090908 -0.141917 -0.073681   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "ENSG00000203995 -0.041181 -0.049788 -0.138405  0.003161 -0.077362 -0.268796   \n",
       "ENSG00000162378 -0.054563  0.081663 -0.094380 -0.077367  0.162979  0.211054   \n",
       "ENSG00000159840 -0.146181  0.025648 -0.097892 -0.253979 -0.038200 -0.027520   \n",
       "ENSG00000074755  0.072423  0.118722 -0.106668 -0.068032 -0.199963  0.035639   \n",
       "ENSG00000036549 -0.080878  0.216868 -0.063773 -0.156554  0.124893  0.034833   \n",
       "\n",
       "                   pc 253    pc 254    pc 255  \n",
       "ENSG00000121410  0.086953  0.075399  0.171969  \n",
       "ENSG00000148584  0.309600  0.048188 -0.178412  \n",
       "ENSG00000175899  0.301693 -0.233983 -0.106899  \n",
       "ENSG00000166535  0.036735  0.038398  0.027567  \n",
       "ENSG00000184389 -0.153174  0.056722  0.097499  \n",
       "...                   ...       ...       ...  \n",
       "ENSG00000203995 -0.067865  0.114491 -0.244308  \n",
       "ENSG00000162378  0.153263 -0.008993  0.012680  \n",
       "ENSG00000159840 -0.011465 -0.018991 -0.073372  \n",
       "ENSG00000074755 -0.043847 -0.208945 -0.020802  \n",
       "ENSG00000036549  0.228654  0.060244  0.142755  \n",
       "\n",
       "[19790 rows x 256 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ee89aa9-2de5-4026-bd0e-446155f2119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cols = [f\"gene {i}\" for i in range(256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c7b20a55-2d1c-4eb0-ad0d-a347d4af7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values_list = [0.0 for _ in range(256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "718fff37-fe4f-4060-879c-5795fec70442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, gene_cols] = new_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1588ec4f-4a18-40c4-8824-297fda6b8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/work/magroup/kaileyhu/synthetic_lethality/utils')\n",
    "\n",
    "from extract_df_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f708ef64-9e9c-4eaa-b399-a9e38704304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_890144/2613948092.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['gene'] = list(map(get_genes_from_index, list(df.index)))\n"
     ]
    }
   ],
   "source": [
    "df['gene'] = list(map(get_genes_from_index, list(df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d23db4a1-6f75-407d-875e-fd088c872ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gene'] = df['gene'].apply(lambda x : x[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "902917fc-d4b3-48ca-8121-f908ff9f4c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2044819/2044819 [04:13<00:00, 8073.41it/s] \n"
     ]
    }
   ],
   "source": [
    "df[gene_cols] = df['gene'].progress_apply(lambda x : pd.Series(list(pca_df.loc[x])) if x in pca_df.index else pd.Series([-100.0 for _ in range(256)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a1f69a54-23f9-43b6-a448-932eb2330cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['gene'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "244b830c-a0b9-444d-ad78-e44254451f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gene 251'] != -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "114a63ee-3b9f-4b40-aa45-65154870c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/work/magroup/kaileyhu/res/perturbed/gf_12L_30M_i2048_SL/PAIR_df\"\n",
    "\n",
    "df.to_hdf(f\"{path}/PAIR_emb_mat.h5\", key = \"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8beb9f6a-d4c5-4890-bb62-46dd2f5f3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/work/magroup/kaileyhu/res/perturbed/gf_12L_30M_i2048_SL/PAIR_df\"\n",
    "name = \"PAIR_general\"\n",
    "\n",
    "df = pd.read_hdf(f\"{path}/PAIR_emb_mat.h5\", \"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d6404-8e68-4248-9f84-b48b90f63022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
